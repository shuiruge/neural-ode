{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQnDPzsYQD3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "34c18a5f-eac9-49f9-94af-fea68da75161"
      },
      "source": [
        "!pip install git+https://github.com/shuiruge/neural-ode.git@master"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/shuiruge/neural-ode.git@master\n",
            "  Cloning https://github.com/shuiruge/neural-ode.git (to revision master) to /tmp/pip-req-build-n3sezri7\n",
            "  Running command git clone -q https://github.com/shuiruge/neural-ode.git /tmp/pip-req-build-n3sezri7\n",
            "Requirement already satisfied (use --upgrade to upgrade): node==0.1.0 from git+https://github.com/shuiruge/neural-ode.git@master in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: node\n",
            "  Building wheel for node (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for node: filename=node-0.1.0-cp36-none-any.whl size=36464 sha256=f2a2088ecbde6123a1fc7ce3b362053f4bacc56f705b3a9ed3f346fdb0c71cb4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qnm0diya/wheels/36/41/e1/1cf7fd120543ff07c299bee3a2ce3fe659795c54f7e03fe9b6\n",
            "Successfully built node\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbpVa7ERQjL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from node.hopfield import ContinuousTimeHopfieldLayer\n",
        "                           \n",
        "# for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "\n",
        "def pooling(x, size):\n",
        "  # x shape: [None, width, height]\n",
        "  x = tf.expand_dims(x, axis=-1)\n",
        "  x = tf.image.resize(x, size)\n",
        "  return x  # shape: [None, size[0], size[1], 1]\n",
        "\n",
        "\n",
        "def process_data(X, y, image_size):\n",
        "  X = pooling(X, image_size)\n",
        "  X = X / 255.\n",
        "  X = tf.where(X < 0.5, -1., 1.)\n",
        "  X = tf.reshape(X, [-1, image_size[0] * image_size[1]])\n",
        "  y = tf.one_hot(y, 10)\n",
        "  return tf.cast(X, tf.float32), tf.cast(y, tf.float32)\n",
        "\n",
        "\n",
        "def create_dataset(X, y, epochs=50):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "  dataset = dataset.shuffle(1000).repeat(epochs).batch(128)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "def create_valid_dataset(X, y, n_samples=3000):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((X[:n_samples], y[:n_samples]))\n",
        "  dataset = dataset.batch(128)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "# load and preprocess MNIST dataset\n",
        "\n",
        "IMAGE_SIZE = (28, 28)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, y_train = process_data(x_train, y_train, IMAGE_SIZE)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZV1tgisBe2e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "814f35c8-1109-400b-ad5a-7703b144df66"
      },
      "source": [
        "benchmark_model = tf.keras.Sequential([\n",
        "  tf.keras.Input([IMAGE_SIZE[0] * IMAGE_SIZE[1]]),\n",
        "  tf.keras.layers.LayerNormalization(),\n",
        "  tf.keras.layers.Dense(1024, activation='relu'),\n",
        "  tf.keras.layers.LayerNormalization(),\n",
        "  tf.keras.layers.Dense(1024, activation='relu'),\n",
        "  tf.keras.layers.LayerNormalization(),\n",
        "  tf.keras.layers.Dense(1024, activation='tanh'),\n",
        "  # tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "benchmark_model.compile(\n",
        "    loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "benchmark_model.fit(create_dataset(x_train, y_train))\n",
        "benchmark_model.evaluate(create_valid_dataset(x_train, y_train))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23438/23438 [==============================] - 80s 3ms/step - loss: 0.0192 - acc: 0.9943\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.0037 - acc: 0.9993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.003667906392365694, 0.9993333220481873]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYLKT6m1HXGr",
        "colab_type": "text"
      },
      "source": [
        "Exame the noise effect:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWy9NB-pRBYq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d4095c35-a17f-4323-e45c-e2b14a31e4ad"
      },
      "source": [
        "FLIP_RATIO = 0.2\n",
        "\n",
        "X = x_train[:1000]\n",
        "targets = np.argmax(y_train[:1000], axis=1)\n",
        "noised_X = np.where(np.random.random(size=X.shape) < FLIP_RATIO,\n",
        "                    -X, X)\n",
        "unoised_y = np.argmax(benchmark_model.predict(X), axis=1)\n",
        "noised_y = np.argmax(benchmark_model.predict(noised_X), axis=1)\n",
        "\n",
        "print('Noise effect (accuracy):',\n",
        "      np.sum(unoised_y == targets) / targets.shape[0],\n",
        "      '=>',\n",
        "      np.sum(noised_y == targets) / targets.shape[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Noise effect (accuracy): 0.999 => 0.698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_v6Q89lYhAX",
        "colab_type": "text"
      },
      "source": [
        "Extract the truncated model from the benchmark:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-Dh7tjUqTVI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ed31c50f-10f8-4818-bfb2-e09aed6cf56d"
      },
      "source": [
        "THRESHOLD = 0.1\n",
        "\n",
        "# truncated model excluding the last classification layer\n",
        "\n",
        "truncated_benchmark_model = tf.keras.Sequential(benchmark_model.layers[:6])\n",
        "unoised_z = truncated_benchmark_model.predict(X)\n",
        "noised_z = truncated_benchmark_model.predict(noised_X)\n",
        "\n",
        "z_flip_ratio = tf.reduce_mean(\n",
        "    tf.where(tf.abs(unoised_z - noised_z) > THRESHOLD, 1., 0.))\n",
        "print('Latent flip ratio:', z_flip_ratio.numpy())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Latent flip ratio: 0.28144237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulHuRK6dDLZP",
        "colab_type": "text"
      },
      "source": [
        "Follow the same process, but for Hopfield layer instead:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sZTvu2pfQi0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a716d94c-3c85-4606-e7b6-5c3e6427670e"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.Input([IMAGE_SIZE[0] * IMAGE_SIZE[1]]),\n",
        "  tf.keras.layers.LayerNormalization(),\n",
        "  tf.keras.layers.Dense(1024, activation='relu'),\n",
        "  tf.keras.layers.LayerNormalization(),\n",
        "  tf.keras.layers.Dense(1024, activation='relu'),\n",
        "  tf.keras.layers.LayerNormalization(),\n",
        "  tf.keras.layers.Dense(1024, activation='tanh'),\n",
        "\n",
        "  # insert Hopfield layers herein\n",
        "  ContinuousTimeHopfieldLayer(reg_factor=10, relax_tol=1e-3),\n",
        "  ContinuousTimeHopfieldLayer(reg_factor=10, relax_tol=1e-3),\n",
        "\n",
        "  tf.keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.fit(create_dataset(x_train, y_train, epochs=50))\n",
        "model.evaluate(create_valid_dataset(x_train[:1000], y_train[:1000]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23438/23438 [==============================] - 108s 5ms/step - loss: 0.0650 - acc: 0.9908\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0514 - acc: 0.9960\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.051423460245132446, 0.9959999918937683]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4pqs8UKgk26",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "3f78ba15-5803-4dd5-efbd-b7b4180dcda4"
      },
      "source": [
        "unoised_y = np.argmax(model.predict(X), axis=1)\n",
        "noised_y = np.argmax(model.predict(noised_X), axis=1)\n",
        "\n",
        "print('Noise effect (accuracy):',\n",
        "      np.sum(unoised_y == targets) / targets.shape[0],\n",
        "      '=>',\n",
        "      np.sum(noised_y == targets) / targets.shape[0])\n",
        "\n",
        "print('Relaxing period:')\n",
        "for layer in model.layers:\n",
        "  if isinstance(layer, ContinuousTimeHopfieldLayer):\n",
        "    print(layer._stop_condition.relax_time.numpy())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Noise effect (accuracy): 0.996 => 0.584\n",
            "Relaxing period:\n",
            "14.192004\n",
            "18.50345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfje0z5a7YLv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3e0ee3f5-51bb-404e-d94c-931d08da487c"
      },
      "source": [
        "# truncated model involving layers before Hopfield layers\n",
        "truncated_model = tf.keras.Sequential(model.layers[:6])\n",
        "unoised_z = truncated_model.predict(X)\n",
        "noised_z = truncated_model.predict(noised_X)\n",
        "\n",
        "z_flip_ratio = tf.reduce_mean(\n",
        "    tf.where(tf.abs(unoised_z - noised_z) > THRESHOLD, 1., 0.))\n",
        "print('Latent flip ratio (without Hopfield):', z_flip_ratio.numpy())\n",
        "\n",
        "\n",
        "# truncated model also includes the Hopfield layers\n",
        "\n",
        "higher_truncated_model = tf.keras.Sequential(model.layers[:8])\n",
        "unoised_z = higher_truncated_model.predict(X)\n",
        "noised_z = higher_truncated_model.predict(noised_X)\n",
        "\n",
        "z_flip_ratio = tf.reduce_mean(\n",
        "    tf.where(tf.abs(unoised_z - noised_z) > THRESHOLD, 1., 0.))\n",
        "print('Latent flip ratio (with Hopfield):', z_flip_ratio.numpy())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Latent flip ratio (without Hopfield): 0.05506543\n",
            "Latent flip ratio (with Hopfield): 0.043288086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELEGDENCO4mp",
        "colab_type": "text"
      },
      "source": [
        "### Temporal Conclusion\n",
        "\n",
        "1. Benchmark model is more stable for random flip perturbation in\n",
        "the final accuracy.\n",
        "1. However, the model with Hopfield layer is significantly more\n",
        "stable in the last latent layer output (also in the layer just\n",
        "before the first Hopfield layer)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfM4j-sWDnCF",
        "colab_type": "text"
      },
      "source": [
        "TODO:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyCfslslDgg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from node.solvers.runge_kutta import RungeKuttaFehlbergSolver\n",
        "from node.core import get_node_function\n",
        "\n",
        "\n",
        "class NodeLayer(tf.keras.layers.Layer):\n",
        "  \n",
        "  # TODO: finish writing this class.\n",
        "\n",
        "  def __init__(self, sub_layers, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.sub_layers = sub_layers\n",
        "  \n",
        "  def build(self, input_shape):\n",
        "    sub_model = tf.keras.Sequential(\n",
        "        {tf.keras.Input(input_shape)} + self.sub_layers)\n",
        "    \n",
        "    def pvf(t, x):\n",
        "      return sub_model(x)\n",
        "\n",
        "    solver = RungeKuttaFehlbergSolver()\n",
        "    self._node_fn = get_node_function(solver, pvf)\n",
        "    super().build(input_shape)\n",
        "  \n",
        "  def call(self, x):\n",
        "    t0 = tf.constant(0.)\n",
        "    t1 = tf.constant(1.)\n",
        "    return self._node_fn(t0, t1, x)\n"
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}