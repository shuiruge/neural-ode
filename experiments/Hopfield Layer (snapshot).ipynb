{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hopfield_layer_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQnDPzsYQD3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "da367ba8-2010-4d22-b6a7-462432931bf8"
      },
      "source": [
        "!pip install git+https://github.com/shuiruge/neural-ode.git@master"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/shuiruge/neural-ode.git@master\n",
            "  Cloning https://github.com/shuiruge/neural-ode.git (to revision master) to /tmp/pip-req-build-l0ogcens\n",
            "  Running command git clone -q https://github.com/shuiruge/neural-ode.git /tmp/pip-req-build-l0ogcens\n",
            "Requirement already satisfied (use --upgrade to upgrade): node==0.1.0 from git+https://github.com/shuiruge/neural-ode.git@master in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: node\n",
            "  Building wheel for node (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for node: filename=node-0.1.0-cp36-none-any.whl size=37076 sha256=957310ad83e3b1dd87c222069289840cfc3b711b6ad804e595610474ffa91a5f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5nycoqq3/wheels/36/41/e1/1cf7fd120543ff07c299bee3a2ce3fe659795c54f7e03fe9b6\n",
            "Successfully built node\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbpVa7ERQjL-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b3a32947-c50d-405b-be44-98acf1fe798a"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from node.hopfield import ContinuousTimeHopfieldLayer\n",
        "                           \n",
        "# for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "\n",
        "IMAGE_SIZE = (28, 28)\n",
        "\n",
        "\n",
        "def pooling(x, size):\n",
        "  # x shape: [None, width, height]\n",
        "  x = tf.expand_dims(x, axis=-1)\n",
        "  x = tf.image.resize(x, size)\n",
        "  return x  # shape: [None, size[0], size[1], 1]\n",
        "\n",
        "\n",
        "def process_data(X, y, image_size):\n",
        "  X = pooling(X, image_size)\n",
        "  X = X / 255.\n",
        "  X = tf.where(X < 0.5, -1., 1.)\n",
        "  X = tf.reshape(X, [-1, image_size[0] * image_size[1]])\n",
        "  y = tf.one_hot(y, 10)\n",
        "  return tf.cast(X, tf.float32), tf.cast(y, tf.float32)\n",
        "\n",
        "\n",
        "def get_benchmark_model(model):\n",
        "  layers = [\n",
        "    layer for layer in model.layers\n",
        "    if not isinstance(layer, ContinuousTimeHopfieldLayer)]\n",
        "  return tf.keras.Sequential(layers)\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.Input([IMAGE_SIZE[0] * IMAGE_SIZE[1]]),\n",
        "  tf.keras.layers.LayerNormalization(),\n",
        "  tf.keras.layers.Dense(1024, activation='relu'),\n",
        "  tf.keras.layers.Dense(512, activation='tanh'),\n",
        "  ContinuousTimeHopfieldLayer(reg_factor=1, relax_tol=1e-3),\n",
        "  tf.keras.layers.Dense(256, activation='tanh'),\n",
        "  ContinuousTimeHopfieldLayer(reg_factor=1, relax_tol=1e-3),\n",
        "  tf.keras.layers.Dense(128, activation='tanh'),\n",
        "  ContinuousTimeHopfieldLayer(reg_factor=1, relax_tol=1e-3),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), _ = mnist.load_data()\n",
        "x_train, y_train = process_data(x_train, y_train, IMAGE_SIZE)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "dataset = dataset.shuffle(1000).repeat(50).batch(128)\n",
        "model.fit(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23438/23438 [==============================] - 87s 4ms/step - loss: 0.0535 - acc: 0.9921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7febcc3a90f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYLKT6m1HXGr",
        "colab_type": "text"
      },
      "source": [
        "Exame the noise effect:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWy9NB-pRBYq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "85a1b323-eb26-423a-fd50-28c39e7675ac"
      },
      "source": [
        "FLIP_RATIO = 0.3\n",
        "\n",
        "benchmark_model = get_benchmark_model(model)\n",
        "\n",
        "def get_hopfield_layer_ids(model):\n",
        "  return [\n",
        "    i for i, layer in enumerate(model.layers)\n",
        "    if isinstance(layer, ContinuousTimeHopfieldLayer)]\n",
        "\n",
        "hid = get_hopfield_layer_ids(model)[-1]\n",
        "\n",
        "X = tf.convert_to_tensor(x_train[-2000:])\n",
        "targets = tf.argmax(tf.convert_to_tensor(y_train[-2000:]), axis=1)\n",
        "noised_X = tf.where(tf.random.uniform(shape=X.shape) < FLIP_RATIO,\n",
        "                    -X, X)\n",
        "unoised_y = tf.argmax(model.predict(X), axis=1)\n",
        "y = tf.argmax(model.predict(noised_X), axis=1)\n",
        "yb = tf.argmax(benchmark_model.predict(noised_X), axis=1)\n",
        "\n",
        "sub_model = tf.keras.Sequential(model.layers[:(hid + 1)])\n",
        "sy1 = sub_model.predict(X)\n",
        "sy2 = sub_model.predict(noised_X)\n",
        "\n",
        "ssub_model = tf.keras.Sequential(model.layers[:hid])\n",
        "ssy1 = ssub_model.predict(X)\n",
        "ssy2 = ssub_model.predict(noised_X)\n",
        "\n",
        "def get_error_ratio(original, noised, threshold=0.2):\n",
        "  diff = original - noised\n",
        "  ratio_per_sample = tf.reduce_mean(\n",
        "    tf.cast(tf.abs(diff) > threshold, tf.float32), axis=1)\n",
        "  return ratio_per_sample\n",
        "\n",
        "num_misleading = 0\n",
        "num_corrected = 0\n",
        "num_uncorrected = 0\n",
        "for i, (err0, err1, ybi, yi, uyi, ti) in enumerate(zip(\n",
        "    get_error_ratio(ssy1, ssy2).numpy(),\n",
        "    get_error_ratio(sy1, sy2).numpy(),\n",
        "    yb, y, unoised_y, targets)):\n",
        "  if yi == uyi and ybi != yi:\n",
        "    num_corrected += 1\n",
        "  elif ybi == uyi and ybi != yi:\n",
        "    num_misleading += 1\n",
        "  elif yi != uyi and ybi == yi:\n",
        "    num_uncorrected += 1\n",
        "  else:\n",
        "    pass\n",
        "  if i < 50:\n",
        "    print(f'{err0:.5f} => {err1:.5f} | {ybi} => {yi} | {uyi} ({ti})')\n",
        "print(\n",
        "  f'misleading: {num_misleading / X.shape[0]}',\n",
        "  f'corrected: {num_corrected / X.shape[0]}',\n",
        "  f'uncorrected: {num_uncorrected / X.shape[0]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.80469 => 0.69531 | 2 => 9 | 2 (2)\n",
            "0.80469 => 0.69531 | 1 => 9 | 2 (3)\n",
            "0.80469 => 0.69531 | 0 => 2 | 9 (0)\n",
            "0.80469 => 0.69531 | 7 => 2 | 9 (4)\n",
            "0.80469 => 0.69531 | 1 => 2 | 9 (9)\n",
            "0.00000 => 0.00000 | 1 => 9 | 9 (5)\n",
            "0.80469 => 0.69531 | 1 => 2 | 9 (9)\n",
            "0.80469 => 0.69531 | 1 => 9 | 2 (6)\n",
            "0.00000 => 0.00000 | 5 => 9 | 9 (1)\n",
            "0.00000 => 0.00000 | 7 => 9 | 9 (7)\n",
            "0.80469 => 0.69531 | 1 => 9 | 2 (6)\n",
            "0.80469 => 0.69531 | 5 => 9 | 2 (8)\n",
            "0.00000 => 0.00000 | 1 => 9 | 9 (0)\n",
            "0.00000 => 0.00000 | 1 => 9 | 9 (9)\n",
            "0.80469 => 0.69531 | 9 => 2 | 9 (0)\n",
            "0.00000 => 0.00000 | 0 => 2 | 2 (0)\n",
            "0.00000 => 0.00000 | 2 => 2 | 2 (6)\n",
            "0.00000 => 0.00000 | 1 => 9 | 9 (1)\n",
            "0.80469 => 0.69531 | 1 => 9 | 2 (4)\n",
            "0.00000 => 0.00000 | 1 => 9 | 9 (2)\n",
            "0.80469 => 0.69531 | 5 => 2 | 9 (8)\n",
            "0.80469 => 0.69531 | 1 => 9 | 2 (3)\n",
            "0.00000 => 0.00000 | 7 => 9 | 9 (1)\n",
            "0.80469 => 0.69531 | 1 => 9 | 2 (4)\n",
            "0.80469 => 0.69531 | 1 => 9 | 2 (8)\n",
            "0.80469 => 0.69531 | 1 => 9 | 2 (5)\n",
            "0.80469 => 0.69531 | 2 => 9 | 2 (2)\n",
            "0.00000 => 0.00000 | 5 => 2 | 2 (6)\n",
            "0.80469 => 0.69531 | 1 => 2 | 9 (8)\n",
            "0.00000 => 0.00000 | 0 => 9 | 9 (7)\n",
            "0.00000 => 0.00000 | 2 => 9 | 9 (2)\n",
            "0.80469 => 0.69531 | 6 => 9 | 2 (8)\n",
            "0.00000 => 0.00000 | 2 => 9 | 9 (2)\n",
            "0.00000 => 0.00000 | 1 => 9 | 9 (1)\n",
            "0.00000 => 0.00000 | 1 => 9 | 9 (9)\n",
            "0.00000 => 0.00000 | 2 => 9 | 9 (0)\n",
            "0.00000 => 0.00000 | 7 => 9 | 9 (0)\n",
            "0.80469 => 0.69531 | 1 => 9 | 2 (4)\n",
            "0.00000 => 0.00000 | 1 => 9 | 9 (0)\n",
            "0.80469 => 0.69531 | 9 => 9 | 2 (5)\n",
            "0.80469 => 0.69531 | 0 => 9 | 2 (5)\n",
            "0.80469 => 0.69531 | 1 => 9 | 2 (6)\n",
            "0.00000 => 0.00000 | 7 => 9 | 9 (7)\n",
            "0.00000 => 0.00000 | 0 => 9 | 9 (6)\n",
            "0.80469 => 0.69531 | 2 => 9 | 2 (2)\n",
            "0.00000 => 0.00000 | 8 => 2 | 2 (3)\n",
            "0.80469 => 0.69531 | 5 => 9 | 2 (8)\n",
            "0.00000 => 0.00000 | 1 => 9 | 9 (4)\n",
            "0.80469 => 0.69531 | 1 => 9 | 2 (3)\n",
            "0.00000 => 0.00000 | 1 => 9 | 9 (4)\n",
            "misleading: 0.0365 corrected: 0.494 uncorrected: 0.037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGsOmvAddQTY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "93d3b8ff-08b7-4142-882b-78e0fd70bd55"
      },
      "source": [
        "for layer in model.layers:\n",
        "  if isinstance(layer, ContinuousTimeHopfieldLayer):\n",
        "    print(layer._stop_condition.relax_time.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80.70676\n",
            "104.49519\n",
            "133.97269\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}