{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from node.base import get_node_function\n",
    "from node.fix_grid import RKSolver\n",
    "\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def dsigmoid(x):\n",
    "    return tf.nn.sigmoid(x) * (1 - tf.nn.sigmoid(x))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def inv_sigmoid(x):\n",
    "    return tf.math.log(x + 1e-8) - tf.math.log(1 - x + 1e-8)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def softmax(x, axis):\n",
    "    return tf.nn.log_softmax(x, axis)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def softmin(x, axis):\n",
    "    return -tf.nn.log_softmax(-x, axis)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def softrescale(x, axis):\n",
    "    max = softmax(x, axis)\n",
    "    min = softmin(x, axis)\n",
    "    return (x - min) / (max - min)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def rescale(x, axis):\n",
    "    max = tf.reduce_max(x, axis, keepdims=True)\n",
    "    min = tf.reduce_min(x, axis, keepdims=True)\n",
    "    return (x - min) / (max - min)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_accuracy(y_true, y_pred):\n",
    "    y_true = tf.argmax(y_true, axis=-1)\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    accuracy = tf.reduce_mean(\n",
    "        tf.where(y_true == y_pred,\n",
    "                 tf.ones_like(y_pred),\n",
    "                 tf.zeros_like(y_pred)))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "input_dim = 28 * 28\n",
    "network = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    # tanh output for bounding the scale of phase vector field\n",
    "    tf.keras.layers.Dense(input_dim, activation='tanh'),\n",
    "])\n",
    "network.build([None, input_dim])\n",
    "\n",
    "\n",
    "class MyLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, network, dt, num_grids, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.network = network\n",
    "        self.dt = dt\n",
    "        self.num_grids = num_grids\n",
    "\n",
    "        t0 = tf.constant(0.)\n",
    "        self.tN = t0 + num_grids * dt\n",
    "\n",
    "#         def pvf(t, x):\n",
    "#             r\"\"\"\n",
    "#             $x^{\\prime} = \\sigma\\left(\\sigma^{-1}(x) + \\Delta t f(t, x; \\theta) \\right)$,\n",
    "#             element-wisely.\n",
    "#             \"\"\"\n",
    "#             return dsigmoid(inv_sigmoid(x)) * self.network(x)\n",
    "\n",
    "        def pvf(t, x):\n",
    "            with tf.GradientTape() as g:\n",
    "                g.watch(x)\n",
    "                f = self.network(x)\n",
    "                r = rescale(x, axis=-1)\n",
    "            return g.gradient(r, [x], [f])[0]\n",
    "\n",
    "        self._pvf = pvf\n",
    "        self._node_fn = get_node_function(RKSolver(self.dt), 0., pvf)\n",
    "\n",
    "    def call(self, x):\n",
    "        y = self._node_fn(self.tN, x)\n",
    "        return y\n",
    "\n",
    "\n",
    "def process(X, y):\n",
    "    X = X / 255.\n",
    "    X = tf.reshape(X, [-1, 28 * 28])\n",
    "    y = tf.one_hot(y, 10)\n",
    "    return tf.cast(X, tf.float32), tf.cast(y, tf.float32)\n",
    "\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train = process(x_train, y_train)\n",
    "x_test, y_test = process(x_test, y_test)\n",
    "\n",
    "my_layer = MyLayer(network, dt=1e-2, num_grids=10)\n",
    "output_layer = tf.keras.layers.Dense(\n",
    "    10, activation='softmax',\n",
    "    kernel_regularizer=tf.keras.regularizers.l2(1.))\n",
    "model = tf.keras.Sequential([my_layer, output_layer])\n",
    "model.build([None, 28 * 28])\n",
    "\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer()\n",
    "loss_fn = tf.losses.CategoricalCrossentropy()\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_one_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(x)\n",
    "        loss = loss_fn(y, outputs)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    accuracy = get_accuracy(y, outputs)\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train(dataset):\n",
    "    step = 0,\n",
    "    loss = float('inf')\n",
    "    reg = float('inf')\n",
    "    accuracy = 0\n",
    "    for x, y in dataset:\n",
    "        loss, accuracy = train_one_step(x, y)\n",
    "        if step % 1 == 0:\n",
    "            tf.print(step, loss, accuracy)\n",
    "        step += 1\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "def clip(min, max, x):\n",
    "    min = np.ones_like(x) * min\n",
    "    max = np.ones_like(x) * max\n",
    "    x = np.where(x < min, min, x)\n",
    "    x = np.where(x > max, max, x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9be28c6b8d00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    556\u001b[0m           \"Cannot iterate over a tensor with unknown first dimension.\")\n\u001b[1;32m    557\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m       \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_shape_as_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m    977\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m  10354\u001b[0m         \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"begin_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10355\u001b[0m         \u001b[0;34m\"ellipsis_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"new_axis_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10356\u001b[0;31m         \"shrink_axis_mask\", shrink_axis_mask)\n\u001b[0m\u001b[1;32m  10357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10358\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "batch_size = 128\n",
    "\n",
    "involved_labels = {1, 3, 5}\n",
    "\n",
    "labels = np.argmax(y_train, axis=-1)\n",
    "\n",
    "X, y = [], []\n",
    "for xi, yi, label in zip(x_train, y_train, labels):\n",
    "    if label in involved_labels:\n",
    "        X.append(xi)\n",
    "        y.append(yi)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(len(X))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "\n",
    "train(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node.utils import tracer\n",
    "\n",
    "def flip(array, ratio):\n",
    "    is_flipped = np.random.random(size=array.shape) < ratio\n",
    "    return np.where(is_flipped, 1 - array, array)\n",
    "\n",
    "t0 = 0.\n",
    "t1 = 1.\n",
    "dt = 1e-2\n",
    "traj_size = int((t1 - t0) / dt) + 1\n",
    "\n",
    "n_data = 20\n",
    "flip_ratio = 0.1\n",
    "\n",
    "trace = tracer(RKSolver(1e-2), my_layer._pvf)\n",
    "trajectories = trace(t0, t1, dt, data)\n",
    "trajectories = tf.transpose(trajectories, [1, 0, 2])\n",
    "trajectories = trajectories.numpy()\n",
    "\n",
    "\n",
    "def get_trajectory(x):\n",
    "    \"\"\"Input shape `[28 * 28]`, output shape `[frames, 28, 28]`.\"\"\"\n",
    "    trajectory = trace(t0, t1, dt, [x]).numpy()[:,0,:]\n",
    "    trajectory = np.reshape(trajectory, [28, 28])\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = output_layer(trajectories[:,-1,:]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "print(preds[i])\n",
    "labels[i], np.argmax(preds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "\n",
    "def rescale(array):\n",
    "    shape = array.shape\n",
    "    y = np.reshape(array, [-1])\n",
    "    y = (y - np.min(y)) / (np.max(y) - np.min(y))\n",
    "    return np.reshape(y, shape)\n",
    "\n",
    "\n",
    "def visualize_trajectory(trajectory):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        trajectory: np.array\n",
    "            Shape `[frames, x_pixal, y_pixal]`.\n",
    "    \n",
    "    Returns: animation.FuncAnimation\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    img = ax.imshow(trajectory[0], cmap='gray')\n",
    "\n",
    "    def init():\n",
    "        img.set_data([[]])\n",
    "        return img,\n",
    "\n",
    "    def animate(i):\n",
    "        y = rescale(trajectory[i])\n",
    "        img.set_data(y)\n",
    "        return img,\n",
    "\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, animate, init_func=init, frames=traj_size, blit=True)\n",
    "    return anim\n",
    "\n",
    "\n",
    "for i, trajectory in enumerate(trajectories):\n",
    "    label = labels[i]\n",
    "    anim = visualize_trajectory(trajectory.reshape([-1, 28, 28]))\n",
    "    anim.save(f'../dat/trajectory/anim_i{i}_l{label}.mp4')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Approach 1\n",
    "\n",
    "~~1. Animation plotting shows that attractors exist for all the displayed instances.~~\n",
    "\n",
    "~~1. By tracing the flipping ratio, we find that, while setting $\\tilde{L} = 3$ in the training process, the flip ratio decreases from $\\sim 0.1$ to $\\sim 0.001$ only after $\\tilde{L} > 30$ approximately for all trials. That is, the static phase vector field is trained without reaching the attractors. And when reaching the attractors, instances in the same class have little difference (but not vanishing), instances from different classes become evidently more distinct.~~\n",
    "\n",
    "~~1. The attractors for the same class, even though close to each other, are far from single. It seems to confirm the conclusion in the study of Hebbian learning that high-dimensional dynamic systems have extremely many attractors.~~\n",
    "\n",
    "1. After re-scaling by `lambda x: (x - min(x)) / (max(x) - min(x))`, there does exists attractors having the properties described above. So, it seems that the phase point flying straightly towords some direction specific for different classes. Or say, \"attracted to the direction\".\n",
    "\n",
    "1. It seems that we encountered the chaos along the phase trajectory.\n",
    "\n",
    "### Approach 2\n",
    "\n",
    "$x^{\\prime} = \\sigma\\left(\\sigma^{-1}(x) + \\Delta t f(t, x; \\theta) \\right)$\n",
    "\n",
    "1. Attractors are reached at $L \\sim 300$.\n",
    "1. There are quite a lot of attractors.\n",
    "1. Indeed, in this case, the $x^{\\alpha} = 0, 1$ for $\\forall \\alpha$ are attractors.\n",
    "1. However, this approach introduces an artificial area of fixed points (i.e. $x^{\\alpha} = 0, 1$ for $\\forall \\alpha$), which is not what we hope for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "1. [Chaos appears in RGE (as a high dimensional non-linear ODE)](https://physics.stackexchange.com/a/55057) (the [paper](https://arxiv.org/abs/hep-th/0304178) related)."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
