{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from node.core import get_node_function\n",
    "from node.solvers import RK4Solver\n",
    "from node.utils.trajectory import tracer\n",
    "from node.hopfield import hopfield, identity\n",
    "\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "DTYPE = 'float32'\n",
    "tf.keras.backend.set_floatx(DTYPE)\n",
    "\n",
    "\n",
    "def process(X, y):\n",
    "    X = X / 255.\n",
    "    X = np.reshape(X, [-1, 28 * 28])\n",
    "    y = np.eye(10)[y]\n",
    "    return X.astype(DTYPE), y.astype(DTYPE)\n",
    "\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train = process(x_train, y_train)\n",
    "x_test, y_test = process(x_test, y_test)\n",
    "\n",
    "scalar = StandardScaler()\n",
    "scalar.fit(x_train)\n",
    "x_train = scalar.transform(x_train)\n",
    "x_test = scalar.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.4483 - accuracy: 0.8815\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.3178 - accuracy: 0.9155\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2941 - accuracy: 0.9198\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2852 - accuracy: 0.9218\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2772 - accuracy: 0.9245\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2729 - accuracy: 0.9259\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2689 - accuracy: 0.9267\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2650 - accuracy: 0.9266\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2640 - accuracy: 0.9284\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2617 - accuracy: 0.9279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb31418e090>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input([28 * 28]),\n",
    "    tf.keras.layers.Dense(64, use_bias=False),  # down-sampling\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "base_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.optimizers.Nadam(1e-3),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "base_model.fit(x_train, y_train, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 41s 691us/sample - loss: 0.3143 - accuracy: 0.9143\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 42s 701us/sample - loss: 0.1305 - accuracy: 0.9620\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 46s 771us/sample - loss: 0.0865 - accuracy: 0.9738\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 45s 756us/sample - loss: 0.0654 - accuracy: 0.9807\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 49s 822us/sample - loss: 0.0556 - accuracy: 0.9831\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 54s 906us/sample - loss: 0.0461 - accuracy: 0.9862\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 54s 908us/sample - loss: 0.0354 - accuracy: 0.9892\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 55s 924us/sample - loss: 0.0336 - accuracy: 0.9899\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 50s 828us/sample - loss: 0.0325 - accuracy: 0.9905\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 55s 915us/sample - loss: 0.0237 - accuracy: 0.9921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb30b0b4650>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NonHopfieldLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units, dt, num_grids, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dt = dt\n",
    "        self.num_grids = num_grids\n",
    "\n",
    "        t0 = tf.constant(0., dtype=DTYPE)\n",
    "        self.tN = t0 + num_grids * dt\n",
    "\n",
    "        self._model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(1024, activation='relu', dtype=DTYPE),\n",
    "            tf.keras.layers.Dense(units, dtype=DTYPE),\n",
    "        ])\n",
    "        self._model.build([None, units])\n",
    "        self._pvf = lambda _, x: self._model(x)\n",
    "\n",
    "        self._node_fn = get_node_function(RK4Solver(self.dt, dtype=DTYPE),\n",
    "                                          tf.constant(0., dtype=DTYPE),\n",
    "                                          self._pvf)\n",
    "\n",
    "    def call(self, x):\n",
    "        y = self._node_fn(self.tN, x)\n",
    "        return y\n",
    "\n",
    "    def get_config(self):\n",
    "        return super().get_config().copy()\n",
    "    \n",
    "\n",
    "non_hopfield_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input([28 * 28]),\n",
    "    tf.keras.layers.Dense(64, use_bias=False),  # down-sampling\n",
    "    NonHopfieldLayer(64, dt=1e-1, num_grids=10),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "non_hopfield_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.optimizers.Nadam(1e-3),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "non_hopfield_model.fit(x_train, y_train, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 88s 1ms/sample - loss: 0.2954 - accuracy: 0.9311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29542918457984924, 0.9310667]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longer_trajectory_non_hopfield_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input([28 * 28]),\n",
    "    tf.keras.layers.Dense(64, use_bias=False),  # down-sampling\n",
    "    NonHopfieldLayer(64, dt=1e-1, num_grids=50),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "longer_trajectory_non_hopfield_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "longer_trajectory_non_hopfield_model.set_weights(non_hopfield_model.get_weights())\n",
    "longer_trajectory_non_hopfield_model.evaluate(x_train, y_train, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 173s 3ms/sample - loss: 0.4003 - accuracy: 0.8871\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 174s 3ms/sample - loss: 0.1850 - accuracy: 0.9470\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 173s 3ms/sample - loss: 0.1312 - accuracy: 0.9611\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 173s 3ms/sample - loss: 0.1034 - accuracy: 0.9689\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 173s 3ms/sample - loss: 0.0829 - accuracy: 0.9745\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 170s 3ms/sample - loss: 0.0682 - accuracy: 0.9792\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 171s 3ms/sample - loss: 0.0567 - accuracy: 0.9836\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 170s 3ms/sample - loss: 0.0474 - accuracy: 0.9859\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 170s 3ms/sample - loss: 0.0402 - accuracy: 0.9888\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 171s 3ms/sample - loss: 0.0332 - accuracy: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb2db2b30d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HopfieldLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units, dt, num_grids, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dt = dt\n",
    "        self.num_grids = num_grids\n",
    "\n",
    "        t0 = tf.constant(0., dtype=DTYPE)\n",
    "        self.tN = t0 + num_grids * dt\n",
    "\n",
    "        self._model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(1024, activation='relu', dtype=DTYPE),\n",
    "            tf.keras.layers.Dense(units, dtype=DTYPE),\n",
    "        ])\n",
    "        self._model.build([None, units])\n",
    "        self._pvf = hopfield(identity, lambda x: tf.reduce_sum(tf.square(self._model(x))))\n",
    "\n",
    "        self._node_fn = get_node_function(RK4Solver(self.dt, dtype=DTYPE),\n",
    "                                          tf.constant(0., dtype=DTYPE),\n",
    "                                          self._pvf)\n",
    "\n",
    "    def call(self, x):\n",
    "        y = self._node_fn(self.tN, x)\n",
    "        return y\n",
    "\n",
    "    def get_config(self):\n",
    "        return super().get_config().copy()\n",
    "\n",
    "\n",
    "hopfield_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input([28 * 28]),\n",
    "    tf.keras.layers.Dense(64, use_bias=False),  # down-sampling\n",
    "    HopfieldLayer(64, dt=1e-1, num_grids=10),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "hopfield_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.optimizers.Nadam(1e-3, epsilon=1e-2),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "hopfield_model.fit(x_train, y_train, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 215s 4ms/sample - loss: 0.0392 - accuracy: 0.9891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03918587080339591, 0.98911667]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longer_trajectory_hopfield_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input([28 * 28]),\n",
    "    tf.keras.layers.Dense(64, use_bias=False),  # down-sampling\n",
    "    HopfieldLayer(64, dt=1e-1, num_grids=50),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "longer_trajectory_hopfield_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "longer_trajectory_hopfield_model.set_weights(hopfield_model.get_weights())\n",
    "longer_trajectory_hopfield_model.evaluate(x_train, y_train, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
